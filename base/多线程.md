#  多线程



<strong>HashMap类</strong>

首先HashMap是线程不安全的，其主要体现：

1.在JDK1.7中，在多线程环境下，扩容时会造成环形链路或数据丢失

2.在JDK1.8中，在多线程环境下，会发生数据覆盖的情况（在putVal()中， 如果没有hash碰撞则直接插入元素）



<strong>ConcurrentHashMap类</strong>

1.在1.8之前采用分段锁，尽量降低同步锁的粒度

2.在1.8之后采用CAS思想代替冗杂的分段锁实现



CAS操作流程：

线程在读取数据时不进行加锁，在准备写回数据时，比较原值是否修改，若未被其他线程修改则写回，若已被修改，则重新执行读取流程，CAS问题又引出了下面的ABA问题



CAS采用乐观锁思想达到lock free，Unsafe的native方法，至于CAS的其他应用可以聊一聊Atomic元子类和一些无锁并发框架(如Amino)，提到ABA问题加分

ABA问题 就是线程1准备将变量的值由A变成B，但是线程2已经把变量A的值变成C，又由C替换成A，这样线程1去操作的时候发现变量的值仍为A，所以CAS成功



针对synchronized获取锁的方式，JVM使用了锁升级的优化方式，就是先使用偏向锁优先同一线程然后再次获取锁，如果失败，就升级为CAS轻量级锁，如果失败则就短暂自旋，防止线程被系统挂起。最后如果以上都失败则就升级为重量级锁



乐观锁的实现会加版本号来对对象记录操作标记，java就用到了AtomicStampedReference类

通过join()保证线程之间的执行顺序



<strong>synchronized</strong>

锁升级的过程：

JDK较早版本OS的资源 互斥量  用户态 -> 内核态的转换 重量级 效率较低

现代版本进行了优化：无锁 -> 偏向锁 -> 轻量级锁（自旋）->  重量级锁



<strong>volatile变量</strong>

* 保证了不同线程对它所修饰的变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对于其他线程来说是立即可见的（实现可见性）
* 禁止进行指令重排序
* volatile只能保证对单次读/写的原子性。i++这种操作不能保证原子性





<strong>ThreadLocal</strong>

以一种空间换时间的说法，在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题



<strong>ReadWriteLock</strong>

如果用ReentrantLock是可以实现线程A在写数据的时候 B在读数据造成的数据不一致问题，

但是如果线程C、线程D也在读数据，数据是不会发生改变的，没有必要进行加锁，没有必要加锁，降低了程序性能

读写锁就是在读锁时共享的，写锁是独占的，提升了读写的性能





<strong>Semaphore</strong>

信号量是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源可以将它比作控制流量的红绿灯，车就是线程，驶入马路就表示线程正在执行，离开马路就表示线程执行完成，看到红灯就表示线程被阻塞，不能执行。

主要方法是acquire和release，acquire每调用一次，许可证数量就减1，如果许可证数量为0，则获取失败，线程进入AQS的等待队列中.





<strong>CountDownLatch</strong>

允许一个或多个线程等待其他线程完成操作



<strong>线程池</strong>

关于线程池线程的分配，要分为IO密集型和CPU密集型，具体介绍可以看相关资料，线程池设置线程数与CPU计算时间和IO操作时间的比例相关，在此可以引出一个配置线程池大小的原则 —— 阻抗匹配原则

> C = CPU数量
>
> P = CPU繁忙时间 / 总运行的时间   // 0<P<1
>
> T = 所需设置的线程数
>
> T = C / P

综上，CPU繁忙的程序越高，设置的线程越少，CPU繁忙时间越低，设置的线程数越高（但也不是无限设置）

线程池顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦







高并发：问题，超员问题处理？